# -*- coding: utf-8 -*-
"""
Created on Mon Mar  2 20:23:47 2020

@author: Pavlos
"""
from keras import optimizers
from tensorflow import keras
import numpy as np 
import matplotlib.pyplot as plt 
import os
import cv2
import random
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dense
from keras.layers import Activation, Dropout
from keras.models import Sequential
from keras import Model


data  = os.path.join("c:", os.sep, "Users", "Pavlos", "Desktop","Leeds","University of Leeds","Year 3","Deep Learning for Medical Image Classification","train")
cat = ["Normal","Pneumonia"]
img_size = 50
train_data = []
for category in cat:
    path = os.path.join(data,category) #path to chest or abd
    class_num = cat.index(category)
    for img in os.listdir(path):
        img_array = cv2.imread(os.path.join(path,img))
        new_array = cv2.resize(img_array,(img_size,img_size))
        train_data.append([new_array,class_num])    
random.shuffle(train_data)
x = [] #train data
y = [] #train labels
for features, label in train_data:
    x.append(features)
    y.append(label)
x = np.array(x)
y = np.array(y)
x = x/ 255
fig = plt.figure(figsize=(15,22))
for i in range(28):
    plt.subplot(10,7,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False    )
    plt.imshow(x[i], cmap=plt.cm.binary)
    plt.xlabel(cat[y[i]],size=18)
    fig.savefig('train.png', bbox_inches = 'tight',
    pad_inches = 0)
plt.show()



v_data  = os.path.join("c:", os.sep, "Users", "Pavlos", "Desktop","Leeds","University of Leeds","Year 3","Deep Learning for Medical Image Classification","val")
cat_v = ["Normal","Pneumonia"]
img_size = 50
val_data = []

for category in cat_v:
    path = os.path.join(v_data,category) #path to chest or abd
    class_num = cat_v.index(category)
    for img in os.listdir(path):
        img_array = cv2.imread(os.path.join(path,img))
        new_array = cv2.resize(img_array,(img_size,img_size))
        val_data.append([new_array,class_num])     
random.shuffle(val_data)
x_val = []
y_val = []
for features, label in val_data:
    x_val.append(features)
    y_val.append(label)
x_val = np.array(x_val)
y_val = np.array(y_val)
x_val = x_val/255

t_data  = os.path.join("c:", os.sep, "Users", "Pavlos", "Desktop","Leeds","University of Leeds","Year 3","Deep Learning for Medical Image Classification","val")
cat_test = ["Normal","Pneumonia"]
img_size = 50
test_data = []

for category in cat_test:
    path = os.path.join(t_data,category) #path to chest or abd
    class_num = cat_test.index(category)
    for img in os.listdir(path):
        img_array = cv2.imread(os.path.join(path,img))
        new_array = cv2.resize(img_array,(img_size,img_size))
        test_data.append([new_array,class_num])     
random.shuffle(test_data)
x_test = []
y_test = []
for features, label in test_data:
    x_test.append(features)
    y_test.append(label)
x_test = np.array(x_test)
y_test = np.array(y_test)
x_test = x_test/255



model = Sequential()
model.add(Conv2D(32, (3, 3), input_shape=x[0].shape))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors
model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(2))
model.add(Activation('sigmoid'))
model.add(Dense(2))
model.add(Activation('softmax'))
print(model.summary())

sgd = optimizers.SGD(lr=0.001, decay=1e-5, momentum=0.99, nesterov=True)
model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])
history=model.fit(x, y,batch_size=64,epochs=50,validation_data=(x_val, y_val))

model.compile(loss='sparse_categorical_crossentropy', optimizer= 'Adam', metrics=['accuracy'])
history1=model.fit(x, y,batch_size=64,epochs=50,validation_data=(x_val, y_val))

ada=keras.optimizers.Adagrad(learning_rate=0.01)
model.compile(loss='sparse_categorical_crossentropy', optimizer=ada, metrics=['accuracy'])
history2=model.fit(x, y,batch_size=32,epochs=50,validation_data=(x_val, y_val))
#
adade=keras.optimizers.Adadelta(learning_rate=1.0)
model.compile(loss='sparse_categorical_crossentropy', optimizer=adade, metrics=['accuracy'])
history3=model.fit(x, y,batch_size=32,epochs=20,validation_data=(x_val, y_val))


from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes
from mpl_toolkits.axes_grid1.inset_locator import mark_inset
# summarize history for 




fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(15,7))
ax1.set_xlabel('Epoch',size=20)
ax1.set_ylabel('Loss',size=20)
ax1.set_title('Model Loss',fontweight="bold", size=20)
ax1.set_ylim([0, 0.7])
ax1.set_xlim([0, 55])
ax1.plot(history.history['loss'],color='red')
ax1.plot(history.history['val_loss'],color='black')
ax1.plot(history1.history['loss'],color='blue')
ax1.plot(history1.history['val_loss'],color='green')
ax1.plot(history2.history['loss'],color='magenta')
ax1.plot(history2.history['val_loss'],color='orange')
ax1.plot(history3.history['loss'],color='saddlebrown')
ax1.plot(history3.history['val_loss'],color='purple')
axins1 = zoomed_inset_axes(ax1, 2,loc = 10, bbox_to_anchor=(0.2,-0.3,0.1,0.2), bbox_transform=fig.transFigure)# zoom = 6
axins1.plot(history.history['loss'],color='red')
axins1.plot(history.history['val_loss'],color='black')
axins1.plot(history1.history['loss'],color='blue')
axins1.plot(history1.history['val_loss'],color='green')
axins1.plot(history2.history['loss'],color='magenta')
axins1.plot(history2.history['val_loss'],color='orange')
axins1.plot(history3.history['loss'],color='saddlebrown')
axins1.plot(history3.history['val_loss'],color='purple')
plt.xticks(fontsize=20)
plt.yticks(fontsize=20)
axins1.set_xlim(15, 50) # Limit the region for zoom
axins1.set_ylim(0.05, 0.25)
mark_inset(ax1, axins1, loc1=1, loc2=2, fc="none", ec="0.5")
ax2.set_xlabel('Epoch',size=20)
ax2.set_ylabel('Accuracy',size=20)
ax2.set_title('Model Accuracy',fontweight="bold", size=20)
ax2.set_ylim([0.5, 1.1])
ax2.set_xlim([0, 55])
ax2.plot(history.history['accuracy'],color='red')
ax2.plot(history.history['val_accuracy'],color='black')
ax2.plot(history1.history['accuracy'],color='blue')
ax2.plot(history1.history['val_accuracy'],color='green')
ax2.plot(history2.history['accuracy'],color='magenta')
ax2.plot(history2.history['val_accuracy'],color='orange')
ax2.plot(history3.history['accuracy'],color='saddlebrown')
ax2.plot(history3.history['val_accuracy'],color='purple')
ax2.legend(['training SGD', 'validation SGD','training Adam', 'validation Adam','training Adagrad'
,'validation Adagrad','training Adadelta', 'validation Adadelta']
,loc='center left', bbox_to_anchor=(1, 0.5),fancybox=True, shadow=True, ncol=1,prop={'size': 20})
axins2 = zoomed_inset_axes(ax2, 2,bbox_to_anchor=(0.9,-0.2,0.1,0.2), bbox_transform=fig.transFigure)
axins2.plot(history.history['accuracy'],color='red')
axins2.plot(history.history['val_accuracy'],color='black')
axins2.plot(history1.history['accuracy'],color='blue')
axins2.plot(history1.history['val_accuracy'],color='green')
axins2.plot(history2.history['accuracy'],color='magenta')
axins2.plot(history2.history['val_accuracy'],color='orange')
axins2.plot(history3.history['accuracy'],color='saddlebrown')
axins2.plot(history3.history['val_accuracy'],color='purple')
plt.xticks(fontsize=20)
plt.yticks(fontsize=20)
axins2.set_xlim(15, 50) # Limit the region for zoom
axins2.set_ylim(0.9, 1.0)
mark_inset(ax2, axins2, loc1=1, loc2=2, fc="none", ec="0.5")
plt.savefig('lossacc.png',bbox_inches='tight')
plt.show()




predictions = model.predict(x_val)
def plot_image(i, predictions_array, true_label, img):
  predictions_array, true_label, img = predictions_array, true_label[i], img[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img)
  
  print(np.argmax(predictions_array))
  
  predicted_label = np.argmax(predictions_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'

  plt.xlabel("{} {:2.0f}% ({})".format(cat_v[predicted_label],
                                100*np.max(predictions_array),
                                cat_v[true_label]),
                                color=color)

def plot_value_array(i, predictions_array, true_label):
  predictions_array, true_label = predictions_array, true_label[i]
  plt.grid(False)
  plt.xticks(range(2))
  plt.yticks([])
  thisplot = plt.bar(range(2), predictions_array, color="#777777")
  plt.ylim([0, 1])
  predicted_label = np.argmax(predictions_array)

  thisplot[predicted_label].set_color('red')
  thisplot[true_label].set_color('blue')
print(predictions[0])



num_rows = 3
num_cols = 3
num_images = num_rows*num_cols
plt.figure(figsize=(3*2*num_cols, 3*num_rows))
for i in range(num_images):
  plt.subplot(num_rows, 2*num_cols, 2*i+1)
  plot_image(i, predictions[i], y_val, x_val)
  plt.subplot(num_rows, 2*num_cols, 2*i+2)
  plot_value_array(i, predictions[i], y_val)
plt.tight_layout()
plt.savefig('valpred.png')
plt.show()

test_predictions = model.predict(x_test)
test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)
print('\nTest accuracy:', test_acc, '\nTest loss:', test_loss)

plt.figure(figsize=(10,5))
for i in range(2):
    plt.subplot(1, 4, 2*i+1)
    plot_image(i, test_predictions[i], y_test, x_test)
    plt.subplot(1, 4, 2*i+2)
    plot_value_array(i, test_predictions[i], y_test)
plt.tight_layout()
plt.savefig('testpred.png')
plt.show()
print()


for layer in model.layers:
    if 'conv' not in layer.name:
        continue
    filters, biases = layer.get_weights()
    print(layer.name, filters.shape)

   
    
filters, biases = model.layers[0].get_weights()
f_min, f_max = filters.min(), filters.max()
filters = (filters - f_min) / (f_max - f_min)

n_filters = 5
ix = 1
for i in range(n_filters):
	f = filters[:, :, :, i]
	for j in range(3):
		ax = plt.subplot(n_filters, 3, ix)
		ax.set_xticks([])
		ax.set_yticks([])
		plt.imshow(f[:, :, j],cmap='gray')
		ix = ix + 1
plt.savefig('filters.png')
plt.show()


img = x[0]
plt.imshow(img,cmap=plt.cm.binary)
plt.savefig('1image.png')
from numpy import expand_dims
from keras.applications.vgg16 import preprocess_input


img = expand_dims(img, axis=0)
img = preprocess_input(img)
convmodel = Model(inputs=model.inputs, outputs=model.layers[0].output)
feature_maps = convmodel.predict(img)

plt.figure(figsize=(15,15))
ix = 1
for _ in range(4):
	for _ in range(8):
		ax = plt.subplot(8, 4, ix)
		ax.set_xticks([])
		ax.set_yticks([])
		plt.imshow(feature_maps[0, :, :, ix-1], cmap='gray')
		ix += 1
plt.savefig('convimages.png')
plt.show()
#2

from keras.callbacks import *
min_lr=1e-7
max_lr=1e-2
step_size = 240
opt = optimizers.SGD(lr=min_lr, momentum=0.9)
model.compile(loss="sparse_categorical_crossentropy", optimizer=opt,
	metrics=["accuracy"])
clr = CyclicLR(
	mode='triangular',
	base_lr=min_lr,
	max_lr=max_lr,
	step_size=step_size)
clr_model = model.fit(x,y, epochs=30,validation_data=(x_val, y_val)
,callbacks=[clr])

import matplotlib

matplotlib.rc('xtick', labelsize=26) 
matplotlib.rc('ytick', labelsize=26)
fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(15,7))
ax1.set_xlabel('Epoch',size=25)
ax1.set_ylabel('Loss',size=25) 
ax1.set_title('Model Loss',fontweight="bold", size=25)
ax1.set_ylim([0, 0.7])
ax1.set_xlim([0, 35])
ax1.plot(clr_model.history['loss'],color='red')
ax1.plot(clr_model.history['val_loss'],color='black')
ax2.set_xlabel('Epoch',size=25)
ax2.set_ylabel('Accuracy',size=25)
ax2.set_title('Model Accuracy',fontweight="bold", size=25)
ax2.set_ylim([0.5, 1.1])
ax2.set_xlim([0, 35])
ax2.plot(clr_model.history['accuracy'],color='red')
ax2.plot(clr_model.history['val_accuracy'],color='black')
ax2.legend(['training triangle', 'validation triangle']
,fancybox=True, shadow=True, ncol=1,prop={'size': 26})
plt.savefig('clr.png')
plt.show()


